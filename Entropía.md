
## Definiciones

## Clásica 
Por Sadi Carnot y Rudolf Clausius
La propiedad interna a un sistema que cambia al ser moverse el calor dentro de el mismo.

## Mecánica estadística
Por Boltzmann
Medida de la proporción de energía en un sistema que puede ser usada.
Mide que tan lejos de [[equilibrio térmico]] un sistema está.
Mide lo especial, o el nivel de orden, en el estado actual de posiciones y velocidades de un sistema.
Es la proporción de estados que son indistinguibles del estado actual.

## Teoría de la información
Por Claude Shanon

La cantidad de información que revela la observación de un evento dentro de un sistema. Cuanto menos probable sea, mayor la entropía del evento.


## Fuentes

![Are you a Boltzmann brain](https://www.youtube.com/watch?v=nhy4Z_32kQo&list=PLsPUh22kYmNCzNFNDwxIug8q1Zz0Mj60H)
![the misunderstood nature of entropy](https://www.youtube.com/watch?v=kfffy12uQ7g)
